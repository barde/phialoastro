name: PR Tests

on:
  pull_request:
    types: [opened, synchronize, reopened]
  merge_group:

permissions:
  contents: read
  pull-requests: write
  actions: write

jobs:
  # Determine which tests to run based on changed files
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      frontend: ${{ steps.filter.outputs.frontend }}
      tests: ${{ steps.filter.outputs.tests }}
      e2e: ${{ steps.filter.outputs.e2e }}
      config: ${{ steps.filter.outputs.config }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Detect file changes
        uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: .github/path-filters.yml

  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: changes
    # Run if: tests changed, frontend changed, config changed, or if it's a merge queue event
    if: |
      needs.changes.outputs.tests == 'true' ||
      needs.changes.outputs.frontend == 'true' ||
      needs.changes.outputs.config == 'true' ||
      github.event_name == 'merge_group'
    permissions:
      contents: read
    outputs:
      coverage: ${{ steps.test-results.outputs.coverage }}
      build-time: ${{ steps.test-results.outputs.build-time }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js 20.x
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
          run_install: false

      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - uses: actions/cache@v4
        name: Setup pnpm cache
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        working-directory: phialo-design
        run: pnpm install --frozen-lockfile

      - name: Run unit tests with coverage
        working-directory: phialo-design
        run: |
          pnpm run test:run -- --coverage --reporter=json --reporter=default
          # Extract coverage percentage
          COVERAGE=$(cat coverage/coverage-summary.json | jq -r '.total.lines.pct' 2>/dev/null || echo "0")
          echo "COVERAGE_PCT=$COVERAGE" >> $GITHUB_ENV

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: phialo-design/coverage

      - name: Build project
        working-directory: phialo-design
        run: |
          BUILD_START=$(date +%s)
          pnpm run build
          BUILD_END=$(date +%s)
          BUILD_TIME=$((BUILD_END - BUILD_START))
          echo "BUILD_TIME=$BUILD_TIME" >> $GITHUB_ENV
          echo "Build completed in ${BUILD_TIME}s"

      - name: Set test results outputs
        id: test-results
        run: |
          echo "coverage=${COVERAGE_PCT:-0}" >> $GITHUB_OUTPUT
          echo "build-time=${BUILD_TIME:-0}" >> $GITHUB_OUTPUT

  e2e:
    name: E2E Tests - Core Scenarios
    runs-on: ubuntu-latest
    needs: changes
    # Run if: e2e changed, frontend changed, config changed, or if it's a merge queue event
    if: |
      needs.changes.outputs.e2e == 'true' ||
      needs.changes.outputs.frontend == 'true' ||
      needs.changes.outputs.config == 'true' ||
      github.event_name == 'merge_group'
    permissions:
      contents: read
    outputs:
      test-time: ${{ steps.e2e-results.outputs.test-time }}
      test-count: ${{ steps.e2e-results.outputs.test-count }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
          run_install: false

      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - uses: actions/cache@v4
        name: Setup pnpm cache
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        working-directory: phialo-design
        run: pnpm install --frozen-lockfile

      # Cache Playwright browsers
      - name: Get Playwright version
        id: playwright-version
        working-directory: phialo-design
        run: echo "version=$(npm ls @playwright/test --json | jq -r '.dependencies["@playwright/test"].version')" >> $GITHUB_OUTPUT

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ steps.playwright-version.outputs.version }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        working-directory: phialo-design
        run: npx playwright install --with-deps chromium firefox webkit

      - name: Install Playwright dependencies
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        working-directory: phialo-design
        run: npx playwright install-deps

      # Run only core E2E tests for PRs
      - name: Run core E2E tests
        working-directory: phialo-design
        run: |
          E2E_START=$(date +%s)
          npx playwright test --config=playwright.pr.config.ts --reporter=json --reporter=line
          E2E_EXIT_CODE=$?
          E2E_END=$(date +%s)
          E2E_TIME=$((E2E_END - E2E_START))
          echo "E2E_TIME=$E2E_TIME" >> $GITHUB_ENV
          # Extract test count from JSON report if available
          if [ -f "test-results.json" ]; then
            TEST_COUNT=$(cat test-results.json | jq '.stats.expected' 2>/dev/null || echo "0")
            echo "TEST_COUNT=$TEST_COUNT" >> $GITHUB_ENV
          else
            echo "TEST_COUNT=0" >> $GITHUB_ENV
          fi
          exit $E2E_EXIT_CODE

      - name: Set E2E results outputs
        id: e2e-results
        run: |
          echo "test-time=${E2E_TIME:-0}" >> $GITHUB_OUTPUT
          echo "test-count=${TEST_COUNT:-0}" >> $GITHUB_OUTPUT

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: phialo-design/test-results
          retention-days: 7

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    needs: [changes, test, e2e]
    if: always()

    steps:
      - name: Check test results
        run: |
          echo "Changes detected:"
          echo "  Frontend: ${{ needs.changes.outputs.frontend }}"
          echo "  Tests: ${{ needs.changes.outputs.tests }}"
          echo "  E2E: ${{ needs.changes.outputs.e2e }}"
          echo "  Config: ${{ needs.changes.outputs.config }}"
          echo ""
          echo "Test Results:"
          echo "  Unit Tests: ${{ needs.test.result }}"
          echo "  E2E Tests: ${{ needs.e2e.result }}"

          # Unit tests are required if they ran
          if [ "${{ needs.test.result }}" == "failure" ]; then
            echo "❌ Unit tests failed!"
            exit 1
          fi

          # E2E tests are required if they ran
          if [ "${{ needs.e2e.result }}" == "failure" ]; then
            echo "❌ E2E tests failed!"
            exit 1
          fi

          # Check if any required tests were skipped when they should have run
          if [ "${{ needs.changes.outputs.config }}" == "true" ] || [ "${{ github.event_name }}" == "merge_group" ]; then
            if [ "${{ needs.test.result }}" == "skipped" ]; then
              echo "❌ Unit tests were skipped but should have run!"
              exit 1
            fi
          fi

          echo "✅ All required tests passed!"

      - name: Comment PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            const changes = {
              frontend: '${{ needs.changes.outputs.frontend }}' === 'true',
              tests: '${{ needs.changes.outputs.tests }}' === 'true',
              e2e: '${{ needs.changes.outputs.e2e }}' === 'true',
              config: '${{ needs.changes.outputs.config }}' === 'true'
            };

            const unitResult = '${{ needs.test.result }}';
            const e2eResult = '${{ needs.e2e.result }}';
            const coverage = '${{ needs.test.outputs.coverage }}' || '0';
            const buildTime = '${{ needs.test.outputs.build-time }}' || '0';
            const e2eTime = '${{ needs.e2e.outputs.test-time }}' || '0';
            const e2eCount = '${{ needs.e2e.outputs.test-count }}' || '0';

            const unitIcon = unitResult === 'success' ? '✅' : unitResult === 'skipped' ? '⏭️' : '❌';
            const e2eIcon = e2eResult === 'success' ? '✅' : e2eResult === 'skipped' ? '⏭️' : '⚠️';

            let changesText = '### Changes Detected\n';
            if (!changes.frontend && !changes.tests && !changes.e2e && !changes.config) {
              changesText += '📄 Documentation or workflow changes only\n';
            } else {
              if (changes.frontend) changesText += '- 🎨 Frontend code\n';
              if (changes.tests) changesText += '- 🧪 Test files\n';
              if (changes.e2e) changesText += '- 🔍 E2E tests\n';
              if (changes.config) changesText += '- ⚙️ Configuration\n';
            }

            // Coverage badge color
            let coverageColor = 'red';
            if (coverage >= 80) coverageColor = 'brightgreen';
            else if (coverage >= 60) coverageColor = 'yellow';
            else if (coverage >= 40) coverageColor = 'orange';

            const comment = `## Test Results

            ${changesText}

            ### Test Execution
            | Test Suite | Status | Details |
            |------------|--------|---------|
            | Unit Tests | ${unitIcon} ${unitResult} | ${unitResult === 'skipped' ? 'No relevant changes' : unitResult === 'success' ? `Coverage: ${coverage}%` : 'Failed'} |
            | E2E Tests | ${e2eIcon} ${e2eResult} | ${e2eResult === 'skipped' ? 'No relevant changes' : `${e2eCount} tests in ${e2eTime}s`} |

            ${unitResult === 'failure' ? '⚠️ **Unit tests must pass before merging!**' : ''}
            ${e2eResult === 'failure' ? '⚠️ **E2E tests must pass before merging!**' : ''}

            ### 📊 Build Metrics
            ${unitResult === 'success' ? `
            - **Test Coverage:** ![Coverage](https://img.shields.io/badge/coverage-${coverage}%25-${coverageColor})
            - **Build Time:** ${buildTime}s
            - **E2E Test Time:** ${e2eTime}s (${e2eCount} tests)
            ` : '
            Build metrics will be available once tests pass.
            '}

            💡 **Performance Insights:**
            - Tests run on Node 20.x with optimized caching
            - Parallel test execution with 4 workers
            - Critical path tests only for faster PR feedback
            `;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('## Test Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

